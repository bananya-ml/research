{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook trains the following ML models:\n",
    "\n",
    "1. Logistic Regressor\n",
    "2. Decision Tree\n",
    "3. Support-Vector Machine\n",
    "4. K-Nearest Neighbours\n",
    "5. Random Forests\n",
    "\n",
    "as well as two boosting methods:\n",
    "\n",
    "1. Extreme Gradient Boosting Machine\n",
    "2. Light Gradient Boosting Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\projects\\research\\.venv\\lib\\site-packages\\dask\\dataframe\\__init__.py:31: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import h5py\n",
    "from loguru import logger\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import Ridge, LinearRegression, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import (RandomForestRegressor, VotingRegressor)\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from lightgbm import LGBMRegressor as lgb\n",
    "from xgboost import XGBRegressor as xgb\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import (mean_squared_error, mean_absolute_error, r2_score, root_mean_squared_error, root_mean_squared_log_error, mean_absolute_percentage_error)\n",
    "from sklearn.model_selection import (cross_validate, KFold, cross_val_score, train_test_split)\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Function to convert RA and Dec to Cartesian coordinates\n",
    "def spherical_to_cartesian(ra, dec, distance=1):\n",
    "    ra_rad = np.radians(ra)\n",
    "    dec_rad = np.radians(dec)\n",
    "    x = distance * np.cos(dec_rad) * np.cos(ra_rad)\n",
    "    y = distance * np.cos(dec_rad) * np.sin(ra_rad)\n",
    "    z = distance * np.sin(dec_rad)\n",
    "    return x, y, z\n",
    "\n",
    "# Sample data\n",
    "ra = [10, 20, 30, 40]  # in degrees\n",
    "dec = [-10, 0, 10, 20] # in degrees\n",
    "\n",
    "# Convert to Cartesian coordinates\n",
    "x, y, z = spherical_to_cartesian(ra, dec)\n",
    "\n",
    "# Plotting\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(x, y, z)\n",
    "\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = '../../../logs'\n",
    "kfold = KFold(n_splits=5)\n",
    "pca = PCA(n_components=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X, y):\n",
    "    \n",
    "    y = pca.fit_transform(y)\n",
    "    mse_scores = []\n",
    "    st = time.time()\n",
    "    for fold, (train_idx, test_idx) in enumerate(kfold.split(X, y)):\n",
    "\n",
    "        print(f\"Training on fold {fold}\")\n",
    "        x_train, x_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        model.fit(x_train, y_train.squeeze(1))\n",
    "        \n",
    "        y_pred = model.predict(x_test)\n",
    "        \n",
    "        # scoring metrics\n",
    "        mse = mean_squared_error(y_test.squeeze(1), y_pred)\n",
    "\n",
    "        print(f\"MSE for fold {fold}: {mse}\")\n",
    "        mse_scores.append(mse)\n",
    "\n",
    "    print(\"Mean MSE:\",np.mean(mse_scores))\n",
    "    \n",
    "\n",
    "    log_file = os.path.join(log_dir, f'train_{model.__class__.__name__}.log')\n",
    "    logger.add(log_file, format=\"{time} - {level} - {message}\")\n",
    "    logger.info(f\"Cross-validation technique:{kfold.__class__.__name__},\\\n",
    "                Number of splits:{kfold.__dict__['n_splits']},\\\n",
    "                Time taken:{time.time()-st},\\\n",
    "                MSE:{mse_scores},\\\n",
    "                Mean MSE:{np.mean(mse_scores)}\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(name:str='', SHUFFLE_FLAG:bool=False, NORM_FLAG:bool=True, random_state:int=42):\n",
    "    '''\n",
    "    Function to select data\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    name: str, (required)\n",
    "        name of dataset to be returned\n",
    "    SHUFFLE_FLAG: bool, (optional)\n",
    "        Flag for if the data should be shuffled\n",
    "    NORM_FLAG: bool, (optional)\n",
    "        If the data should be normalized\n",
    "    random_state: int, (optional)\n",
    "        random_state\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    X: numpy.ndarray \n",
    "        training set \n",
    "    y: numpy.ndarray \n",
    "        test set\n",
    "    '''\n",
    "    \n",
    "    if name is None:\n",
    "        raise ValueError(\"Required argument 'name' is missing.\")\n",
    "    \n",
    "    if name == \"gaia\":\n",
    "        dir = '../data/Gaia DR3/gaia_lm_m_stars.parquet'\n",
    "        data = pd.read_parquet(dir)\n",
    "        if SHUFFLE_FLAG:\n",
    "            df = shuffle(data)\n",
    "        else:\n",
    "            df = data\n",
    "        X = np.vstack(df['flux'])\n",
    "        y = np.vstack(df['Cat'])\n",
    "        \n",
    "        y = np.where(y == 'M', 1, y)\n",
    "        y = np.where(y == 'LM', 0, y)\n",
    "\n",
    "        y = y.astype(int)\n",
    "\n",
    "        if NORM_FLAG:\n",
    "            norm = np.linalg.norm(X,keepdims=True)\n",
    "            X = X/norm\n",
    "            \n",
    "\n",
    "    elif name == 'apogee':\n",
    "        dir = '../../../data/APOGEE'\n",
    "        train_dir = dir + '/training_data.h5'\n",
    "        tets_dir = dir +'/test_data.h5'\n",
    "\n",
    "        with h5py.File(train_dir, 'r') as f:\n",
    "            X = f['spectrum'][:]\n",
    "            y = np.hstack((f['TEFF'],\n",
    "                        f['LOGG'],\n",
    "                        f['FE_H']))\n",
    "        \n",
    "        #TODO: add shuffle\n",
    "\n",
    "        if NORM_FLAG:\n",
    "            norm_dir = dir + '/mean_and_std.npy'\n",
    "            norm_data = np.load(norm_dir)\n",
    "            \n",
    "            mean = norm_data[0]\n",
    "            std = norm_data[1]\n",
    "            y = (y-mean)/std\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of spectra: 44784\n",
      "Number of bins in each spectra: 7214\n"
     ]
    }
   ],
   "source": [
    "#X, y = get_data('gaia', SHUFFLE_FLAG=True)\n",
    "X, y = get_data('apogee')\n",
    "\n",
    "num_samples = X.shape[0]\n",
    "spectrum_width = X.shape[1]\n",
    "\n",
    "num_samples_m = np.count_nonzero(y)\n",
    "num_samples_lm = len(y) - num_samples_m\n",
    "num_classes = len(np.unique(y))\n",
    "\n",
    "print(\"Total number of spectra:\", num_samples)\n",
    "print(\"Number of bins in each spectra:\", spectrum_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "train_model(lr, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr = DecisionTreeRegressor()\n",
    "train_model(dtr, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor()\n",
    "train_model(rfr, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsRegressor()\n",
    "train_model(knn, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Light Gradient Boosting Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold 0\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 3.865823 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1839570\n",
      "[LightGBM] [Info] Number of data points in the train set: 35827, number of used features: 7214\n",
      "[LightGBM] [Info] Start training from score 0.001407\n",
      "MSE for fold 0: 0.011321316591446471\n",
      "Training on fold 1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 3.943052 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1839570\n",
      "[LightGBM] [Info] Number of data points in the train set: 35827, number of used features: 7214\n",
      "[LightGBM] [Info] Start training from score 0.002391\n",
      "MSE for fold 1: 0.009775777811238371\n",
      "Training on fold 2\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 3.550972 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1839570\n",
      "[LightGBM] [Info] Number of data points in the train set: 35827, number of used features: 7214\n",
      "[LightGBM] [Info] Start training from score 0.000719\n",
      "MSE for fold 2: 0.01067043287345182\n",
      "Training on fold 3\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 4.257694 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1839570\n",
      "[LightGBM] [Info] Number of data points in the train set: 35827, number of used features: 7214\n",
      "[LightGBM] [Info] Start training from score -0.003108\n",
      "MSE for fold 3: 0.011385926848572142\n",
      "Training on fold 4\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 3.778441 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1839570\n",
      "[LightGBM] [Info] Number of data points in the train set: 35828, number of used features: 7214\n",
      "[LightGBM] [Info] Start training from score -0.001408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-05-22 18:13:15.602\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mCross-validation technique:KFold,                Number of splits:5,                Time taken:624.9241380691528,                MSE:[0.011321316591446471, 0.009775777811238371, 0.01067043287345182, 0.011385926848572142, 0.010112977260240071],                Mean MSE:0.010653286276989773\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for fold 4: 0.010112977260240071\n",
      "Mean MSE: 0.010653286276989773\n"
     ]
    }
   ],
   "source": [
    "lgbm = lgb()\n",
    "train_model(lgbm, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extreme Gradient Boosting Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold 0\n",
      "MSE for fold 0: 0.015175866894423962\n",
      "Training on fold 1\n",
      "MSE for fold 1: 0.012978886254131794\n",
      "Training on fold 2\n",
      "MSE for fold 2: 0.014031355269253254\n",
      "Training on fold 3\n",
      "MSE for fold 3: 0.014668754301965237\n",
      "Training on fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-05-22 18:34:50.912\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mCross-validation technique:KFold,                Number of splits:5,                Time taken:1294.7455422878265,                MSE:[0.015175867, 0.012978886, 0.014031355, 0.014668754, 0.013670755],                Mean MSE:0.014105123467743397\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for fold 4: 0.013670754618942738\n",
      "Mean MSE: 0.0141051235\n"
     ]
    }
   ],
   "source": [
    "xgbm = xgb()\n",
    "train_model(xgbm, X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
