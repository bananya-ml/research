{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook trains the following ML models:\n",
    "\n",
    "1. Logistic Regressor\n",
    "2. Decision Tree\n",
    "3. Support-Vector Machine\n",
    "4. K-Nearest Neighbours\n",
    "5. Random Forests\n",
    "\n",
    "as well as two boosting methods:\n",
    "\n",
    "1. Extreme Gradient Boosting Machine\n",
    "2. Light Gradient Boosting Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from loguru import logger\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (RandomForestClassifier, VotingClassifier)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import (LGBMClassifier as lgb, plot_importance)\n",
    "from xgboost import XGBClassifier as xgb\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report, mean_squared_error, roc_auc_score, confusion_matrix)\n",
    "from sklearn.model_selection import (cross_validate, RepeatedStratifiedKFold, cross_val_score, train_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = '../logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(name:str='', SHUFFLE_FLAG:bool=False, NORM_FLAG:bool=True, random_state:int=42):\n",
    "    '''\n",
    "    Function to select data\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    name: str, (required)\n",
    "        name of dataset to be returned\n",
    "    SHUFFLE_FLAG: bool, (optional)\n",
    "        Flag for if the data should be shuffled\n",
    "    NORM_FLAG: bool, (optional)\n",
    "        If the data should be normalized\n",
    "    random_state: int, (optional)\n",
    "        random_state\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    X: numpy.ndarray \n",
    "        training set \n",
    "    y: numpy.ndarray \n",
    "        test set\n",
    "    '''\n",
    "    \n",
    "    if name is None or name not in ['gaia']:\n",
    "        raise ValueError(\"Required argument 'name' is missing.\")\n",
    "    \n",
    "    if name == \"gaia\":\n",
    "        dir = '../data/Gaia DR3/gaia_lm_m_stars.parquet'\n",
    "        data = pd.read_parquet(dir)\n",
    "        if SHUFFLE_FLAG:\n",
    "            df = shuffle(data)\n",
    "        else:\n",
    "            df = data\n",
    "        X = np.vstack(df['flux'])\n",
    "        y = np.vstack(df['Cat'])\n",
    "        \n",
    "        y = np.where(y == 'M', 1, y)\n",
    "        y = np.where(y == 'LM', 0, y)\n",
    "\n",
    "        y = y.astype(int)\n",
    "\n",
    "        if NORM_FLAG:\n",
    "            norm = np.linalg.norm(X,keepdims=True)\n",
    "            X = X/norm\n",
    "            \n",
    "\n",
    "    elif name == 'apogee':\n",
    "        dir = '../data/APOGEE'\n",
    "        train_dir = dir + '/training_data.h5'\n",
    "        test_dir = dir +'/test_data.h5'\n",
    "\n",
    "        with h5py.File(train_dir, 'r') as f:\n",
    "            X = f['spectrum'][:]\n",
    "            y = np.hstack((f['TEFF'],\n",
    "                        f['LOGG'],\n",
    "                        f['FE_H']))\n",
    "        \n",
    "        #TODO: add shuffle\n",
    "\n",
    "        if NORM_FLAG:\n",
    "            norm_dir = dir + '/mean_and_std.npy'\n",
    "            norm_data = np.load(norm_dir)\n",
    "            \n",
    "            mean = norm_data[0]\n",
    "            std = norm_data[1]\n",
    "            y = (y-mean)/std\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of spectra: 17627\n",
      "Number of bins in each spectra: 343\n",
      "In the dataset, we have 11026 spectra for low mass stars and 6601 spectra for high mass stars.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = get_data('gaia', SHUFFLE_FLAG=True)\n",
    "#X, y = get_data('apogee')\n",
    "\n",
    "num_samples = X.shape[0]\n",
    "spectrum_width = X.shape[1]\n",
    "\n",
    "num_samples_m = np.count_nonzero(y)\n",
    "num_samples_lm = len(y) - num_samples_m\n",
    "num_classes = len(np.unique(y))\n",
    "\n",
    "print(\"Total number of spectra:\", num_samples)\n",
    "print(\"Number of bins in each spectra:\", spectrum_width)\n",
    "print(\"In the dataset, we have\", num_samples_lm, \"spectra for low mass stars and\", num_samples_m, \"spectra for high mass stars.\")\n",
    "\n",
    "plt.bar([\"Low-mass stars\", \"High-mass stars\"],[num_samples_lm, num_samples_m], color=['#1f77b4', '#ff7f0e'])\n",
    "plt.ylabel(\"Number of samples\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#naive splitting methods, not used in this notebook\n",
    "\n",
    "split = 0.8\n",
    "\n",
    "train_size = int(split * num_samples)\n",
    "\n",
    "x_train, x_test = np.split(X, [train_size])\n",
    "y_train, y_test = np.split(y, [train_size])\n",
    "\n",
    "#x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = RepeatedStratifiedKFold(n_splits=10, n_repeats=2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-05-09 15:34:55.927\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mCross-validation technique:RepeatedStratifiedKFold,            Number of repeats:2,            Number of splits:10,            Time taken:1.4197499752044678,            ROC-AUC scores:[0.9466990851397017, 0.9402016538915904, 0.9445053435533943, 0.9518530728866178, 0.9447622187422732, 0.9453556416385065, 0.9367687961099473, 0.9474220425672331, 0.9455219160754551, 0.9482139910905791, 0.9351342069837083, 0.95045743014918, 0.9472499244484739, 0.9503310530509078, 0.9424640786834803, 0.9485027061182999, 0.9382322335129911, 0.9410012099213552, 0.9477685200461969, 0.9509541879777814],            Mean ROC-AUC score:0.9451699656293837,            Accuracy:[0.6256381168462848, 0.6256381168462848, 0.6256381168462848, 0.6256381168462848, 0.6256381168462848, 0.6256381168462848, 0.6250709018718095, 0.6254256526674233, 0.6254256526674233, 0.6254256526674233, 0.6256381168462848, 0.6256381168462848, 0.6256381168462848, 0.6256381168462848, 0.6256381168462848, 0.6256381168462848, 0.6250709018718095, 0.6254256526674233, 0.6254256526674233, 0.6254256526674233],            Mean accuracy:0.625517656095179\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ROC-AUC score: 0.9451699656293837\n",
      "Mean accuracy: 0.625517656095179\n"
     ]
    }
   ],
   "source": [
    "# training with no hyperparamater tuning\n",
    "\n",
    "accuracy_scores = []\n",
    "roc_auc_scores = []\n",
    "st = time.time()\n",
    "for train_idx, test_idx in kfold.split(X, y):\n",
    "    \n",
    "    x_train, x_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    model = LogisticRegression()\n",
    "    model.fit(x_train, y_train.squeeze(1))\n",
    "\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_probs = model.predict_proba(x_test)[:,1]\n",
    "    accuracy = accuracy_score(y_test.squeeze(1), y_pred)\n",
    "    ra_score = roc_auc_score(y_test.squeeze(1), y_probs)\n",
    "\n",
    "    roc_auc_scores.append(ra_score)\n",
    "    accuracy_scores.append(accuracy)\n",
    "\n",
    "print(\"Mean ROC-AUC score:\",np.mean(roc_auc_scores))\n",
    "print(\"Mean accuracy:\",np.mean(accuracy_scores))\n",
    "\n",
    "log_file = os.path.join(log_dir, f'train_{model.__class__.__name__}.log')\n",
    "logger.add(log_file, format=\"{time} - {level} - {message}\")\n",
    "logger.info(f\"Cross-validation technique:{kfold.__class__.__name__},\\\n",
    "            Number of repeats:{kfold.__dict__['n_repeats']},\\\n",
    "            Number of splits:{kfold.__dict__['cvargs']['n_splits']},\\\n",
    "            Time taken:{time.time()-st},\\\n",
    "            ROC-AUC scores:{roc_auc_scores},\\\n",
    "            Mean ROC-AUC score:{np.mean(roc_auc_scores)},\\\n",
    "            Accuracy:{accuracy_scores},\\\n",
    "            Mean accuracy:{np.mean(accuracy_scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8856353013784883\n",
      "0.9263065259338283\n"
     ]
    }
   ],
   "source": [
    "# training with no hyperparamater tuning\n",
    "\n",
    "accuracy_scores = []\n",
    "roc_auc_scores = []\n",
    "st = time.time()\n",
    "for train_idx, test_idx in kfold.split(X, y):\n",
    "    \n",
    "    x_train, x_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    model = DecisionTreeClassifier()\n",
    "    model.fit(x_train, y_train.squeeze(1))\n",
    "\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_probs = model.predict_proba(x_test)[:,1]\n",
    "    accuracy = accuracy_score(y_test.squeeze(1), y_pred)\n",
    "    ra_score = roc_auc_score(y_test.squeeze(1), y_probs)\n",
    "\n",
    "    roc_auc_scores.append(ra_score)\n",
    "    accuracy_scores.append(accuracy)\n",
    "\n",
    "print(\"Mean ROC-AUC score:\",np.mean(roc_auc_scores))\n",
    "print(\"Mean accuracy:\",np.mean(accuracy_scores))\n",
    "\n",
    "log_file = os.path.join(log_dir, f'train_{model.__class__.__name__}.log')\n",
    "logger.add(log_file, format=\"{time} - {level} - {message}\")\n",
    "logger.info(f\"Cross-validation technique:{kfold.__class__.__name__},\\\n",
    "            Number of repeats:{kfold.__dict__['n_repeats']},\\\n",
    "            Number of splits:{kfold.__dict__['cvargs']['n_splits']},\\\n",
    "            Time taken:{time.time()-st},\\\n",
    "            ROC-AUC scores:{roc_auc_scores},\\\n",
    "            Mean ROC-AUC score:{np.mean(roc_auc_scores)},\\\n",
    "            Accuracy:{accuracy_scores},\\\n",
    "            Mean accuracy:{np.mean(accuracy_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training with no hyperparamater tuning\n",
    "\n",
    "accuracy_scores = []\n",
    "roc_auc_scores = []\n",
    "st = time.time()\n",
    "for train_idx, test_idx in kfold.split(X, y):\n",
    "    \n",
    "    x_train, x_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(x_train, y_train.squeeze(1))\n",
    "\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_probs = model.predict_proba(x_test)[:,1]\n",
    "    accuracy = accuracy_score(y_test.squeeze(1), y_pred)\n",
    "    ra_score = roc_auc_score(y_test.squeeze(1), y_probs)\n",
    "\n",
    "    roc_auc_scores.append(ra_score)\n",
    "    accuracy_scores.append(accuracy)\n",
    "\n",
    "print(\"Mean ROC-AUC score:\",np.mean(roc_auc_scores))\n",
    "print(\"Mean accuracy:\",np.mean(accuracy_scores))\n",
    "\n",
    "log_file = os.path.join(log_dir, f'train_{model.__class__.__name__}.log')\n",
    "logger.add(log_file, format=\"{time} - {level} - {message}\")\n",
    "logger.info(f\"Cross-validation technique:{kfold.__class__.__name__},\\\n",
    "            Number of repeats:{kfold.__dict__['n_repeats']},\\\n",
    "            Number of splits:{kfold.__dict__['cvargs']['n_splits']},\\\n",
    "            Time taken:{time.time()-st},\\\n",
    "            ROC-AUC scores:{roc_auc_scores},\\\n",
    "            Mean ROC-AUC score:{np.mean(roc_auc_scores)},\\\n",
    "            Accuracy:{accuracy_scores},\\\n",
    "            Mean accuracy:{np.mean(accuracy_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 1000)\n",
    "    max_depth = trial.suggest_int('max_depth', 1 , 50)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 1, 32)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 32)\n",
    "\n",
    "    model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf)\n",
    "\n",
    "    rkf = RepeatedStratifiedKFold(n_splits = 5)\n",
    "    score = cross_val_score(model, x_train, y_train.squeeze(1), cv=rkf, scoring='accuracy')\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='maximize', study_name='xgb_model_training')\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support-Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training with no hyperparamater tuning\n",
    "\n",
    "accuracy_scores = []\n",
    "roc_auc_scores = []\n",
    "st = time.time()\n",
    "for train_idx, test_idx in kfold.split(X, y):\n",
    "    \n",
    "    x_train, x_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    model = LogisticRegression()\n",
    "    model.fit(x_train, y_train.squeeze(1))\n",
    "\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_probs = model.predict_proba(x_test)[:,1]\n",
    "    accuracy = accuracy_score(y_test.squeeze(1), y_pred)\n",
    "    ra_score = roc_auc_score(y_test.squeeze(1), y_probs)\n",
    "\n",
    "    roc_auc_scores.append(ra_score)\n",
    "    accuracy_scores.append(accuracy)\n",
    "\n",
    "print(\"Mean ROC-AUC score:\",np.mean(roc_auc_scores))\n",
    "print(\"Mean accuracy:\",np.mean(accuracy_scores))\n",
    "\n",
    "log_file = os.path.join(log_dir, f'train_{model.__class__.__name__}.log')\n",
    "logger.add(log_file, format=\"{time} - {level} - {message}\")\n",
    "logger.info(f\"Cross-validation technique:{kfold.__class__.__name__},\\\n",
    "            Number of repeats:{kfold.__dict__['n_repeats']},\\\n",
    "            Number of splits:{kfold.__dict__['cvargs']['n_splits']},\\\n",
    "            Time taken:{time.time()-st},\\\n",
    "            ROC-AUC scores:{roc_auc_scores},\\\n",
    "            Mean ROC-AUC score:{np.mean(roc_auc_scores)},\\\n",
    "            Accuracy:{accuracy_scores},\\\n",
    "            Mean accuracy:{np.mean(accuracy_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training with no hyperparamater tuning\n",
    "\n",
    "accuracy_scores = []\n",
    "roc_auc_scores = []\n",
    "st = time.time()\n",
    "for train_idx, test_idx in kfold.split(X, y):\n",
    "    \n",
    "    x_train, x_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    model = KNeighborsClassifier()\n",
    "    model.fit(x_train, y_train.squeeze(1))\n",
    "\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_probs = model.predict_proba(x_test)[:,1]\n",
    "    accuracy = accuracy_score(y_test.squeeze(1), y_pred)\n",
    "    ra_score = roc_auc_score(y_test.squeeze(1), y_probs)\n",
    "\n",
    "    roc_auc_scores.append(ra_score)\n",
    "    accuracy_scores.append(accuracy)\n",
    "\n",
    "print(\"Mean ROC-AUC score:\",np.mean(roc_auc_scores))\n",
    "print(\"Mean accuracy:\",np.mean(accuracy_scores))\n",
    "\n",
    "log_file = os.path.join(log_dir, f'train_{model.__class__.__name__}.log')\n",
    "logger.add(log_file, format=\"{time} - {level} - {message}\")\n",
    "logger.info(f\"Cross-validation technique:{kfold.__class__.__name__},\\\n",
    "            Number of repeats:{kfold.__dict__['n_repeats']},\\\n",
    "            Number of splits:{kfold.__dict__['cvargs']['n_splits']},\\\n",
    "            Time taken:{time.time()-st},\\\n",
    "            ROC-AUC scores:{roc_auc_scores},\\\n",
    "            Mean ROC-AUC score:{np.mean(roc_auc_scores)},\\\n",
    "            Accuracy:{accuracy_scores},\\\n",
    "            Mean accuracy:{np.mean(accuracy_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Light Gradient Boosting Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------initial naive implementation, needs a lot more tuning-------------------------------\n",
    "\n",
    "# training with no hyperparamater tuning\n",
    "\n",
    "accuracy_scores = []\n",
    "roc_auc_scores = []\n",
    "st = time.time()\n",
    "for train_idx, test_idx in kfold.split(X, y):\n",
    "    \n",
    "    x_train, x_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    model = lgb(n_estimators=1200, random_state=42, learning_rate = 0.01,reg_lambda=50, min_child_samples=2400, num_leaves=95, colsample_bytree=0.19, max_bins=65, device='gpu')\n",
    "    model.fit(x_train, y_train.squeeze(1))\n",
    "\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_probs = model.predict_proba(x_test)[:,1]\n",
    "    accuracy = accuracy_score(y_test.squeeze(1), y_pred)\n",
    "    ra_score = roc_auc_score(y_test.squeeze(1), y_probs)\n",
    "\n",
    "    roc_auc_scores.append(ra_score)\n",
    "    accuracy_scores.append(accuracy)\n",
    "\n",
    "print(\"Mean ROC-AUC score:\",np.mean(roc_auc_scores))\n",
    "print(\"Mean accuracy:\",np.mean(accuracy_scores))\n",
    "\n",
    "log_file = os.path.join(log_dir, f'train_{model.__class__.__name__}.log')\n",
    "logger.add(log_file, format=\"{time} - {level} - {message}\")\n",
    "logger.info(f\"Cross-validation technique:{kfold.__class__.__name__},\\\n",
    "            Number of repeats:{kfold.__dict__['n_repeats']},\\\n",
    "            Number of splits:{kfold.__dict__['cvargs']['n_splits']},\\\n",
    "            Time taken:{time.time()-st},\\\n",
    "            ROC-AUC scores:{roc_auc_scores},\\\n",
    "            Mean ROC-AUC score:{np.mean(roc_auc_scores)},\\\n",
    "            Accuracy:{accuracy_scores},\\\n",
    "            Mean accuracy:{np.mean(accuracy_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check overfitting\n",
    "y_pred_train = model.predict(x_train)\n",
    "acc_train = accuracy_score(y_train, y_pred_train)\n",
    "print(accuracy, acc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extreme Gradient Boosting Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------initial naive implementation, needs a lot more tuning-------------------------------\n",
    "\n",
    "accuracy_scores = []\n",
    "roc_auc_scores = []\n",
    "st = time.time()\n",
    "for train_idx, test_idx in kfold.split(X, y):\n",
    "    \n",
    "    x_train, x_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    model = xgb(n_estimators=1000, learning_rate=0.05, early_stopping_rounds=5, device='gpu')\n",
    "    model.fit(x_train, y_train.squeeze(1))\n",
    "\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_probs = model.predict_proba(x_test)[:,1]\n",
    "    accuracy = accuracy_score(y_test.squeeze(1), y_pred)\n",
    "    ra_score = roc_auc_score(y_test.squeeze(1), y_probs)\n",
    "\n",
    "    roc_auc_scores.append(ra_score)\n",
    "    accuracy_scores.append(accuracy)\n",
    "\n",
    "print(\"Mean ROC-AUC score:\",np.mean(roc_auc_scores))\n",
    "print(\"Mean accuracy:\",np.mean(accuracy_scores))\n",
    "\n",
    "log_file = os.path.join(log_dir, f'train_{model.__class__.__name__}.log')\n",
    "logger.add(log_file, format=\"{time} - {level} - {message}\")\n",
    "logger.info(f\"Cross-validation technique:{kfold.__class__.__name__},\\\n",
    "            Number of repeats:{kfold.__dict__['n_repeats']},\\\n",
    "            Number of splits:{kfold.__dict__['cvargs']['n_splits']},\\\n",
    "            Time taken:{time.time()-st},\\\n",
    "            ROC-AUC scores:{roc_auc_scores},\\\n",
    "            Mean ROC-AUC score:{np.mean(roc_auc_scores)},\\\n",
    "            Accuracy:{accuracy_scores},\\\n",
    "            Mean accuracy:{np.mean(accuracy_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        'booster': trial.suggest_categorical('booster', ['gbtree','gblinear']),\n",
    "        'device': 'cuda',\n",
    "        'grow_policy': trial.suggest_categorical('grow_policy', ['depthwise','lossguide']),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.1),\n",
    "        'gamma' : trial.suggest_float('gamma', 1e-5, 0.5, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.3, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.3, 1.0),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 7),\n",
    "        'lambda': trial.suggest_float('lambda', 1e-3, 10.0, log=True),\n",
    "        'alpha': trial.suggest_float('alpha', 1e-3, 10.0, log=True),\n",
    "    }\n",
    "\n",
    "    params['n_estimators'] = 3000\n",
    "    params['early_stopping_rounds'] = 50\n",
    "    params['booster'] = 'gbtree'\n",
    "    params[\"verbosity\"] = 0\n",
    "    params['tree_method'] = \"hist\"\n",
    "    \n",
    "    auc_scores = []\n",
    "\n",
    "    for train_idx, valid_idx in cv.split(X, y):\n",
    "\n",
    "        X_train_fold, X_valid_fold = pd.DataFrame(X).iloc[train_idx], pd.DataFrame(X).iloc[valid_idx]\n",
    "        y_train_fold, y_valid_fold = pd.Series(y.squeeze(1)).iloc[train_idx], pd.Series(y.squeeze(1)).iloc[valid_idx]\n",
    "                \n",
    "        # Create and fit the model\n",
    "        model = xgb(**params)\n",
    "        model.fit(X_train_fold, y_train_fold, eval_set=[(X_valid_fold, y_valid_fold)],verbose=False)\n",
    "\n",
    "        # Predict class probabilities\n",
    "        y_prob = model.predict_proba(X_valid_fold)\n",
    "\n",
    "        # Compute the AUC for each class and take the average\n",
    "        average_auc = roc_auc_score(pd.Series(y.squeeze(1)).iloc[valid_idx], y_prob.squeeze(1), multi_class=\"ovr\", average=\"macro\")\n",
    "        auc_scores.append(average_auc)\n",
    "\n",
    "    # Return the average AUC score across all folds\n",
    "    return np.mean(auc_scores)\n",
    "\n",
    "study = optuna.create_study(direction='maximize', study_name='xgb_model_training')\n",
    "study.optimize(objective, n_trials=200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
