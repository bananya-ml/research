{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../../') # Add the root directory to sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from models.starnet import StarNet\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../data/Gaia DR3/train.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet(data_dir)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.drop(columns = ['teff_gspphot', 'logg_gspphot', 'mh_gspphot', 'spectraltype_esphs'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rerun this cell to see random examples of different spectra\n",
    "\n",
    "\n",
    "# Random sample from 'M' category (massive star)\n",
    "sample_ms = df[df['Cat'] == 'M'].sample(n=1).index\n",
    "flux_ms = df['flux'].iloc[sample_ms].values[0]\n",
    "object_id_ms = df['source_id'].iloc[sample_ms].values[0]\n",
    "\n",
    "# Random sample from 'LM' category (low-mass star)\n",
    "sample_lm = df[df['Cat'] == 'LM'].sample(n=1).index\n",
    "flux_lm = df['flux'].iloc[sample_lm].values[0]\n",
    "object_id_lm = df['source_id'].iloc[sample_lm].values[0]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot for 'M' category (massive star)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(flux_ms)\n",
    "plt.title(f\"Massive Star ({object_id_ms})\")\n",
    "plt.xlabel('Wavelength (nm)')\n",
    "plt.ylabel('Magnitude')\n",
    "\n",
    "# Plot for 'LM' category (low-mass star)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(flux_lm)\n",
    "plt.title(f\"Low-Mass Star ({object_id_lm})\")\n",
    "plt.xlabel('Wavelength (nm)')\n",
    "plt.ylabel('Magnitude')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = df.shape[0]\n",
    "spectrum_width = len(df['flux'][0])\n",
    "\n",
    "num_samples_lm = df['Cat'].value_counts()['LM']\n",
    "num_samples_m = df['Cat'].value_counts()['M']\n",
    "num_classes = df['Cat'].nunique()\n",
    "\n",
    "print(\"Number of total spectral samples:\", num_samples)\n",
    "print(\"Number of bins in each spectra:\", spectrum_width)\n",
    "print(\"In the dataset, we have\", num_samples_lm, \"spectra for low mass stars and\", num_samples_m, \"spectra for high mass stars.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack(df['flux'])\n",
    "y = np.vstack(df['Cat'])\n",
    "\n",
    "# encode categories to int\n",
    "y = torch.from_numpy(np.where(y == 'M', 1, np.where(y == 'LM', 0, y)).astype(float))\n",
    "\n",
    "# L2 normalization\n",
    "X = torch.from_numpy(X/np.linalg.norm(X,keepdims=True)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv1d) or isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, x_train, y_train, x_val, y_val, prt_steps = 1, verbose=True):\n",
    "    \n",
    "    # initialize weights\n",
    "    model.apply(init_weights)\n",
    "\n",
    "    # hyperparameters\n",
    "    epochs = 200\n",
    "    learning_rate = 1e-4\n",
    "    batch_size = 64\n",
    "    device = 'cuda'\n",
    "    \n",
    "    # model components\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # move everything to gpu\n",
    "    model.to(device)\n",
    "    x_train = x_train.to(device)\n",
    "    y_train = y_train.to(device)\n",
    "    x_val = x_val.to(device)\n",
    "    y_val = y_val.to(device)\n",
    "\n",
    "    # metrics\n",
    "    training_losses, validation_losses = [], []\n",
    "    accuracy = []\n",
    "    \n",
    "    # lr cycling\n",
    "    max_lr = 1e-2\n",
    "    steps_per_epoch = len(x_train) // batch_size\n",
    "    scheduler = OneCycleLR(optimizer, max_lr=max_lr, steps_per_epoch=steps_per_epoch, epochs=epochs)\n",
    "\n",
    "    batch_start = torch.arange(0, len(x_train), batch_size)\n",
    "\n",
    "    for epoch in tqdm(range(epochs), desc='Epochs', dynamic_ncols=True):\n",
    "        \n",
    "        model.train()\n",
    "        running_loss = 0\n",
    "\n",
    "        for start in batch_start:\n",
    "\n",
    "            x_batch = x_train[start:start+batch_size]\n",
    "            y_batch = y_train[start:start+batch_size]\n",
    "            \n",
    "            output = model(x_batch.unsqueeze(1))\n",
    "            loss = criterion(output, y_batch)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            running_loss += loss.item() * x_batch.size(0)\n",
    "\n",
    "        train_loss = running_loss / len(x_train)\n",
    "        training_losses.append(train_loss)\n",
    "        if verbose and (epoch+1) % prt_steps == 0:\n",
    "            print(f'Train loss: {train_loss:.4f}', end='\\r')\n",
    "\n",
    "\n",
    "        model.eval()\n",
    "        preds, labels = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            output = model(x_val.unsqueeze(1))\n",
    "            loss = criterion(output, y_val)\n",
    "\n",
    "            probs = torch.sigmoid(output)\n",
    "            pred = torch.round(probs).cpu().numpy().astype(float)  # pred: [batch_size]\n",
    "            \n",
    "            preds.extend(pred)\n",
    "            labels.extend(y_val.cpu().numpy())\n",
    "            \n",
    "            val_loss = loss.item()\n",
    "        \n",
    "        epoch_acc = accuracy_score(labels, preds)\n",
    "\n",
    "        validation_losses.append(val_loss)\n",
    "        accuracy.append(epoch_acc)\n",
    "        \n",
    "        if verbose and (epoch+1) % prt_steps == 0:\n",
    "            print(f'Train loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Accuracy: {epoch_acc:.4f}', end='\\r')    \n",
    "            \n",
    "    return training_losses, validation_losses, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=5)\n",
    "\n",
    "training_losses, validation_losses, accuracy_scores = [], [], []\n",
    "\n",
    "params = {\n",
    "    'num_fluxes':spectrum_width, \n",
    "    'filter_length':3, \n",
    "    'pool_length':4,\n",
    "    'num_filters':[4,16],\n",
    "    'num_hidden':[256,128],\n",
    "    'num_labels':y.size(1)\n",
    "}\n",
    "\n",
    "model = StarNet(**params)\n",
    "print(model)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(X, y)):\n",
    "    \n",
    "    print(f\"\\nFitting fold {fold+1}\")\n",
    "\n",
    "    tr_loss, val_loss, acc = fit_model(model, X[train_idx], y[train_idx], X[val_idx], y[val_idx])\n",
    "    training_losses.append(tr_loss)\n",
    "    validation_losses.append(val_loss)\n",
    "    accuracy_scores.append(acc)\n",
    "\n",
    "training_losses = np.mean(training_losses, axis=0)\n",
    "validation_losses = np.mean(validation_losses, axis=0)\n",
    "accuracy_scores = np.mean(accuracy_scores, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 14))\n",
    "    \n",
    "ax1.plot(accuracy_scores, label='Validation Accuracy')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.set_title('Accuracy')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(training_losses, label='Training Loss')\n",
    "ax2.plot(validation_losses, label='Validation Loss')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.set_title('Training and Validation Loss')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
