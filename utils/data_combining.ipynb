{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import dask.dataframe as dd\n",
    "\n",
    "from astropy.io.votable import parse_single_table\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download coordinate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources_file = '../data/Gaia DR3/queries/impartial sources coord-result.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5937173300407375616</td>\n",
       "      <td>250.247043</td>\n",
       "      <td>-51.593826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5937081353758582016</td>\n",
       "      <td>251.645316</td>\n",
       "      <td>-51.613334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5937201200518016768</td>\n",
       "      <td>250.622534</td>\n",
       "      <td>-51.278547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5937201200518017024</td>\n",
       "      <td>250.616240</td>\n",
       "      <td>-51.279443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5937081388118319616</td>\n",
       "      <td>251.626566</td>\n",
       "      <td>-51.625500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             source_id          ra        dec\n",
       "0  5937173300407375616  250.247043 -51.593826\n",
       "1  5937081353758582016  251.645316 -51.613334\n",
       "2  5937201200518016768  250.622534 -51.278547\n",
       "3  5937201200518017024  250.616240 -51.279443\n",
       "4  5937081388118319616  251.626566 -51.625500"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sources_df = pd.read_csv(sources_file)\n",
    "sources_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources_df_dd = dd.from_pandas(sources_df, npartitions=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine coordinates and spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "impartial_sources = '../data/Gaia DR3/spectra/XP_temp'\n",
    "files = glob.glob(f'{impartial_sources}/*.vot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this loop works\n",
    "pattern = re.compile(r'(\\d+)(?=\\.vot$)')\n",
    "spectra_df = pd.DataFrame(columns=['source_id', 'flux'])\n",
    "\n",
    "for f in files[:500]:\n",
    "    match = pattern.search(os.path.basename(f))\n",
    "    if match:\n",
    "        source_id = match.group()\n",
    "        \n",
    "        impartial_data = parse_single_table(f).to_table().to_pandas()\n",
    "        flux_array = impartial_data['flux'].values\n",
    "        \n",
    "        temp_df = pd.DataFrame({'source_id': [int(source_id)], 'flux': [flux_array]})\n",
    "        \n",
    "        spectra_df = pd.concat([spectra_df, temp_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this loop also works\n",
    "\n",
    "pattern = re.compile(r'(\\d+)(?=\\.vot$)')\n",
    "data = []\n",
    "\n",
    "for f in files[:500]:\n",
    "    match = pattern.search(os.path.basename(f))\n",
    "    if match:\n",
    "        source_id = int(match.group())\n",
    "        impartial_data = parse_single_table(f).to_table().to_pandas()\n",
    "        flux_array = impartial_data['flux'].values\n",
    "        data.append({'source_id': source_id, 'flux': flux_array})\n",
    "\n",
    "spectra_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following file cannot be read: XP_SAMPLED_Gaia_DR3_5888623436756684288.vot\n",
      "Batch processing completed. All files combined into 'final_combined.parquet'. Temp directory deleted.\n"
     ]
    }
   ],
   "source": [
    "# Ensure the './temp' directory exists\n",
    "os.makedirs('./temp', exist_ok=True)\n",
    "\n",
    "pattern = re.compile(r'(\\d+)(?=\\.vot$)')\n",
    "batch_size = 500\n",
    "\n",
    "# Process files in batches, skipping already processed files\n",
    "for i in range(0, len(files), batch_size):\n",
    "    batch_files = files[i:i + batch_size]\n",
    "    batch_filename = f'./temp/{i}_{i + len(batch_files)}.parquet'\n",
    "\n",
    "    # Skip processing if the batch file already exists\n",
    "    if os.path.exists(batch_filename):\n",
    "        print(f\"Skipping batch {i}-{i + len(batch_files)}, already processed.\")\n",
    "        continue\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for f in batch_files:\n",
    "        match = pattern.search(os.path.basename(f))\n",
    "        if match:\n",
    "            try:\n",
    "                source_id = int(match.group())\n",
    "                impartial_data = parse_single_table(f).to_table().to_pandas()\n",
    "                flux_array = impartial_data['flux'].values\n",
    "                data.append({'source_id': source_id, 'flux': flux_array})\n",
    "            except:\n",
    "                print(f\"The following file cannot be read: {os.path.basename(f)}\")    \n",
    "    # Create a DataFrame for the current batch\n",
    "    spectra_df = pd.DataFrame(data)\n",
    "    \n",
    "    # Save the batch to a Parquet file\n",
    "    spectra_df.to_parquet(batch_filename, index=False)\n",
    "    \n",
    "    # Clear the list to free memory\n",
    "    del data\n",
    "    del spectra_df\n",
    "\n",
    "# Combine all batch Parquet files into one final Parquet file\n",
    "all_files = [os.path.join('./temp', f) for f in os.listdir('./temp') if f.endswith('.parquet')]\n",
    "combined_df = pd.concat((pd.read_parquet(f) for f in all_files), ignore_index=True)\n",
    "\n",
    "# Save the final combined DataFrame as Parquet\n",
    "combined_df.to_parquet('./final_combined.parquet', index=False)\n",
    "\n",
    "# Delete the './temp' directory and its contents\n",
    "#shutil.rmtree('./temp')\n",
    "\n",
    "print(\"Batch processing completed. All files combined into 'final_combined.parquet'. Temp directory deleted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask import delayed, compute\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "pattern = re.compile(r'(\\d+)(?=\\.vot$)')\n",
    "\n",
    "@delayed\n",
    "def process_file(f):\n",
    "    match = pattern.search(os.path.basename(f))\n",
    "    if match:\n",
    "        source_id = int(match.group())\n",
    "        impartial_data = parse_single_table(f).to_table().to_pandas()\n",
    "        flux_array = impartial_data['flux'].values\n",
    "        return {'source_id': source_id, 'flux': flux_array}\n",
    "    return None\n",
    "\n",
    "file_paths = files[:500]  # Assuming files is your list of file paths\n",
    "\n",
    "# Create a list of delayed tasks\n",
    "tasks = [process_file(f) for f in file_paths]\n",
    "\n",
    "# Compute the results in parallel\n",
    "results = compute(*tasks)\n",
    "\n",
    "# Filter out None results\n",
    "results = [r for r in results if r is not None]\n",
    "\n",
    "# Create the DataFrame\n",
    "spectra_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra_df_dd = dd.from_pandas(spectra_df, npartitions=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = dd.merge(sources_df, spectra_df, on='source_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.merge(sources_df, spectra_df, on='source_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>flux</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1106487002561770368</td>\n",
       "      <td>99.334608</td>\n",
       "      <td>68.892552</td>\n",
       "      <td>[9.1753686e-17, 1.0186828e-16, 9.4628383e-17, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1103461593236932480</td>\n",
       "      <td>98.830491</td>\n",
       "      <td>64.092667</td>\n",
       "      <td>[8.479949e-17, 1.4802934e-16, 2.1828411e-16, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1101665025596084864</td>\n",
       "      <td>107.524509</td>\n",
       "      <td>65.940173</td>\n",
       "      <td>[-2.0176978e-17, -3.659598e-18, 1.4074245e-17,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1106844034603972352</td>\n",
       "      <td>94.147552</td>\n",
       "      <td>68.677752</td>\n",
       "      <td>[1.2871195e-17, 8.22262e-18, 9.0978916e-18, 9....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1105449304102685312</td>\n",
       "      <td>90.625299</td>\n",
       "      <td>67.979417</td>\n",
       "      <td>[1.4120433e-17, 1.2651873e-17, 1.2261003e-17, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>125153392797464832</td>\n",
       "      <td>50.341736</td>\n",
       "      <td>32.590031</td>\n",
       "      <td>[3.9062817e-17, 4.8551608e-17, 4.5109008e-17, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>123712001772784640</td>\n",
       "      <td>47.857266</td>\n",
       "      <td>31.584668</td>\n",
       "      <td>[6.2166747e-18, 3.3648442e-18, 3.6364879e-19, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1091965271455414272</td>\n",
       "      <td>122.749021</td>\n",
       "      <td>65.222823</td>\n",
       "      <td>[7.8339155e-16, 7.036686e-16, 9.255116e-16, 7....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1095175330012281216</td>\n",
       "      <td>121.694347</td>\n",
       "      <td>66.488818</td>\n",
       "      <td>[4.3393175e-16, 3.0278368e-16, 2.9516192e-16, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1090460074396428672</td>\n",
       "      <td>127.535351</td>\n",
       "      <td>62.462151</td>\n",
       "      <td>[6.12923e-18, 5.883068e-18, 3.5268e-18, 3.9331...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              source_id          ra        dec  \\\n",
       "0   1106487002561770368   99.334608  68.892552   \n",
       "1   1103461593236932480   98.830491  64.092667   \n",
       "2   1101665025596084864  107.524509  65.940173   \n",
       "3   1106844034603972352   94.147552  68.677752   \n",
       "4   1105449304102685312   90.625299  67.979417   \n",
       "..                  ...         ...        ...   \n",
       "95   125153392797464832   50.341736  32.590031   \n",
       "96   123712001772784640   47.857266  31.584668   \n",
       "97  1091965271455414272  122.749021  65.222823   \n",
       "98  1095175330012281216  121.694347  66.488818   \n",
       "99  1090460074396428672  127.535351  62.462151   \n",
       "\n",
       "                                                 flux  \n",
       "0   [9.1753686e-17, 1.0186828e-16, 9.4628383e-17, ...  \n",
       "1   [8.479949e-17, 1.4802934e-16, 2.1828411e-16, 1...  \n",
       "2   [-2.0176978e-17, -3.659598e-18, 1.4074245e-17,...  \n",
       "3   [1.2871195e-17, 8.22262e-18, 9.0978916e-18, 9....  \n",
       "4   [1.4120433e-17, 1.2651873e-17, 1.2261003e-17, ...  \n",
       "..                                                ...  \n",
       "95  [3.9062817e-17, 4.8551608e-17, 4.5109008e-17, ...  \n",
       "96  [6.2166747e-18, 3.3648442e-18, 3.6364879e-19, ...  \n",
       "97  [7.8339155e-16, 7.036686e-16, 9.255116e-16, 7....  \n",
       "98  [4.3393175e-16, 3.0278368e-16, 2.9516192e-16, ...  \n",
       "99  [6.12923e-18, 5.883068e-18, 3.5268e-18, 3.9331...  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
